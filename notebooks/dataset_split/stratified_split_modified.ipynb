{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "with open(\"dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Identify and remove invalid self-room pairs\n",
    "invalid_pairs = {(\"kitchen\", \"kitchen\"), (\"terrace\", \"terrace\"), (\"bedroom\", \"bedroom\"),\n",
    "                 (\"corridor\", \"corridor\"), (\"study room\", \"study room\"),\n",
    "                 (\"store room\", \"store room\"), (\"prayer room\", \"prayer room\")}\n",
    "\n",
    "data = [entry for entry in data if tuple(sorted(entry[\"rooms\"])) not in invalid_pairs]\n",
    "\n",
    "# Group dataset by (intent, room combination, action combination)\n",
    "grouped_data = defaultdict(list)\n",
    "for entry in data:\n",
    "    room_key = tuple(sorted(entry[\"rooms\"]))  # Sorted tuple ensures consistency\n",
    "    action_key = tuple(sorted((action[\"room\"], action[\"action\"]) for action in entry[\"actions\"]))\n",
    "    key = (entry[\"intent\"], room_key, action_key)\n",
    "    grouped_data[key].append(entry)\n",
    "\n",
    "# Initialize split sets\n",
    "train_set, val_set, test_set = [], [], []\n",
    "\n",
    "# Perform stratified split while keeping multi-room commands intact\n",
    "for key, samples in grouped_data.items():\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    if num_samples == 1:\n",
    "        print(f\"⚠ Warning: Category {key} has only 1 sample. Assigning to training set.\")\n",
    "        train_set.extend(samples)\n",
    "        continue\n",
    "\n",
    "    if num_samples < 5:\n",
    "        print(f\"⚠ Warning: Category {key} has very few samples ({num_samples}). Oversampling.\")\n",
    "        samples.extend(random.choices(samples, k=5 - num_samples))  # Oversample to at least 5 examples\n",
    "\n",
    "    train, temp = train_test_split(samples, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42)\n",
    "\n",
    "    train_set.extend(train)\n",
    "    val_set.extend(val)\n",
    "    test_set.extend(test)\n",
    "\n",
    "# Function to compute category distribution in the dataset\n",
    "def compute_distribution(dataset, name):\n",
    "    counter = Counter((entry[\"intent\"], tuple(sorted(entry[\"rooms\"])), \n",
    "                       tuple(sorted((action[\"room\"], action[\"action\"]) for action in entry[\"actions\"]))) \n",
    "                      for entry in dataset)\n",
    "    \n",
    "    print(f\"\\n{name} set distribution:\")\n",
    "    for category, count in counter.items():\n",
    "        print(f\"  {category}: {count} samples\")\n",
    "\n",
    "# Display distributions to verify balance\n",
    "compute_distribution(train_set, \"Train\")\n",
    "compute_distribution(val_set, \"Validation\")\n",
    "compute_distribution(test_set, \"Test\")\n",
    "\n",
    "# Save the split datasets\n",
    "with open(\"train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_set, f, indent=4)\n",
    "with open(\"val.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_set, f, indent=4)\n",
    "with open(\"test.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_set, f, indent=4)\n",
    "\n",
    "print(f\"\\n✅ Dataset split complete: {len(train_set)} train, {len(val_set)} val, {len(test_set)} test samples\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
